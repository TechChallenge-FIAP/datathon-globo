{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iy5tD_RDyhbB"
   },
   "outputs": [],
   "source": [
    "!unzip /content/challenge-webmedia-e-globo-2023.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25614,
     "status": "ok",
     "timestamp": 1740355783271,
     "user": {
      "displayName": "Bruno Melo",
      "userId": "00641391951095617493"
     },
     "user_tz": 180
    },
    "id": "kWeycLjhSVV8",
    "outputId": "ec2da9ce-27c9-4717-9ad6-c0e7f62ad111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2104,
     "status": "ok",
     "timestamp": 1740355820945,
     "user": {
      "displayName": "Bruno Melo",
      "userId": "00641391951095617493"
     },
     "user_tz": 180
    },
    "id": "RFUXk_PLbGT7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1740355822253,
     "user": {
      "displayName": "Bruno Melo",
      "userId": "00641391951095617493"
     },
     "user_tz": 180
    },
    "id": "HS6yUNuryJAH"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1740355844473,
     "user": {
      "displayName": "Bruno Melo",
      "userId": "00641391951095617493"
     },
     "user_tz": 180
    },
    "id": "YXDwOvp9yKRM"
   },
   "outputs": [],
   "source": [
    "user_path = \"/content/drive/MyDrive/Faculdade/Pos_EngML/DataThon/datathon_files/files/treino\"\n",
    "site_path = \"/content/drive/MyDrive/Faculdade/Pos_EngML/DataThon/datathon_files/itens/itens\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inqOuLM4zP53"
   },
   "source": [
    "# Carregar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 26321,
     "status": "ok",
     "timestamp": 1740356354508,
     "user": {
      "displayName": "Bruno Melo",
      "userId": "00641391951095617493"
     },
     "user_tz": 180
    },
    "id": "ng-I_3EByx3L"
   },
   "outputs": [],
   "source": [
    "user_files = glob.glob(os.path.join(user_path, \"*.csv\"))\n",
    "usuarios = pd.concat((pd.read_csv(f) for f in user_files), ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVTcUMAHzJkF"
   },
   "outputs": [],
   "source": [
    "site_files = glob.glob(os.path.join(site_path, \"*.csv\"))\n",
    "site = pd.concat((pd.read_csv(f) for f in site_files), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kkum5z5TzUTD"
   },
   "outputs": [],
   "source": [
    "validacao = pd.read_csv('/content/validacao.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3qogabSwoWQ"
   },
   "outputs": [],
   "source": [
    "# Pré-processamento dos dados de usuários\n",
    "def parse_lista(valor):\n",
    "    return [item.strip() for item in str(valor).split(',')]\n",
    "\n",
    "def processar_usuarios(df):\n",
    "    # Converter colunas de histórico em listas\n",
    "    list_columns = ['history', 'timestampHistory', 'numberOfClicksHistory',\n",
    "                   'timeOnPageHistory', 'scrollPercentageHistory', 'pageVisitsCountHistory']\n",
    "\n",
    "    for col in list_columns:\n",
    "        df[col] = df[col].apply(parse_lista)\n",
    "\n",
    "    # Criar características agregadas\n",
    "    df['total_cliques'] = df['numberOfClicksHistory'].apply(lambda x: sum(map(int, x)))\n",
    "    df['tempo_medio'] = df['timeOnPageHistory'].apply(lambda x: np.mean(list(map(int, x))))\n",
    "    df['scroll_medio'] = df['scrollPercentageHistory'].apply(lambda x: np.mean(list(map(float, x))))\n",
    "    df['visitas_total'] = df['pageVisitsCountHistory'].apply(lambda x: sum(map(int, x)))\n",
    "\n",
    "    return df\n",
    "\n",
    "usuarios_processados = processar_usuarios(usuarios)\n",
    "\n",
    "# Engenharia de características\n",
    "features = usuarios_processados[['total_cliques', 'tempo_medio', 'scroll_medio', 'visitas_total']]\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Clusterização com KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "usuarios_processados['cluster'] = kmeans.fit_predict(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RC7o_G1yzrwg"
   },
   "outputs": [],
   "source": [
    "site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4G3X4hD1DAr"
   },
   "outputs": [],
   "source": [
    "!python3 -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1T234wX0mqk"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"pt_core_news_sm\")\n",
    "portuguese_stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ixe2IzcDzn9-"
   },
   "outputs": [],
   "source": [
    "# Pré-processamento de texto\n",
    "site['conteudo'] = site['title'] + ' ' + site['caption'] + ' ' + site['body']\n",
    "tfidf = TfidfVectorizer(stop_words=list(portuguese_stopwords))\n",
    "tfidf_matrix = tfidf.fit_transform(site['conteudo'])\n",
    "\n",
    "# Mapeamento de IDs para índices\n",
    "indices = pd.Series(site.index, index=site['page']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tU0bdNRg1SPg"
   },
   "outputs": [],
   "source": [
    "class SistemaRecomendacao:\n",
    "    def __init__(self, usuarios, site, clusters):\n",
    "        self.usuarios = usuarios\n",
    "        self.site = site\n",
    "        self.clusters = clusters\n",
    "        self.carregar_dados()\n",
    "\n",
    "    def carregar_dados(self):\n",
    "        # Popularidade por cluster\n",
    "        self.popularidade_cluster = {}\n",
    "        for cluster in self.clusters.unique():\n",
    "            historico_cluster = self.usuarios[self.usuarios['cluster'] == cluster]['history'].explode()\n",
    "            self.popularidade_cluster[cluster] = historico_cluster.value_counts().to_dict()\n",
    "\n",
    "        # Matriz de similaridade\n",
    "        self.cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "    def recomendar_por_cluster(self, cluster, n=10):\n",
    "        return list(self.popularidade_cluster.get(cluster, {}).keys())[:n]\n",
    "\n",
    "    def recomendar_por_conteudo(self, page_id, n=10):\n",
    "        idx = indices.get(page_id)\n",
    "        if idx is None: return []\n",
    "        sim_scores = list(enumerate(self.cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_indices = [i[0] for i in sim_scores[1:n+1]]\n",
    "        return self.site['Page'].iloc[sim_indices].tolist()\n",
    "\n",
    "    def recomendar_hibrido(self, user_id, n=20):\n",
    "        # Verificar se é usuário existente\n",
    "        usuario = self.usuarios[self.usuarios['userId'] == user_id]\n",
    "\n",
    "        if not usuario.empty:\n",
    "            cluster = usuario['cluster'].values[0]\n",
    "            historico = usuario['history'].values[0]\n",
    "        else:\n",
    "            cluster = np.random.choice(self.clusters.unique())\n",
    "            historico = []\n",
    "\n",
    "        # Recomendações baseadas em cluster\n",
    "        rec_cluster = self.recomendar_por_cluster(cluster, n//2)\n",
    "\n",
    "        # Recomendações baseadas em conteúdo\n",
    "        rec_conteudo = []\n",
    "        if historico:\n",
    "            for artigo in historico[:3]:  # Considerar últimos 3 artigos\n",
    "                rec_conteudo += self.recomendar_por_conteudo(artigo, 5)\n",
    "\n",
    "        # Combinação e desduplicação\n",
    "        recomendacoes = list(dict.fromkeys(rec_cluster + rec_conteudo))\n",
    "        return recomendacoes[:n]\n",
    "\n",
    "# Inicializar sistema\n",
    "sistema = SistemaRecomendacao(usuarios_processados, site, usuarios_processados['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xFfpBkhN1WW9"
   },
   "outputs": [],
   "source": [
    "# Função para gerar recomendações para o conjunto de validação\n",
    "def gerar_recomendacoes_validacao(df_validacao, sistema):\n",
    "    recomendacoes = []\n",
    "    for _, row in df_validacao.iterrows():\n",
    "        user_id = row['userId']\n",
    "        rec = sistema.recomendar_hibrido(user_id)\n",
    "        recomendacoes.append({\n",
    "            'userId': user_id,\n",
    "            'recomendacoes': rec\n",
    "        })\n",
    "    return pd.DataFrame(recomendacoes)\n",
    "\n",
    "# Gerar recomendações finais\n",
    "recomendacoes_finais = gerar_recomendacoes_validacao(validacao, sistema)\n",
    "print(recomendacoes_finais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTdojPQ21X2t"
   },
   "outputs": [],
   "source": [
    "# Atualizar popularidade considerando recência\n",
    "def atualizar_recencia(site, peso_recencia=0.5):\n",
    "    data_atual = pd.Timestamp.now()\n",
    "    site['idade_dias'] = (data_atual - pd.to_datetime(site['issued'])).dt.days\n",
    "    site['peso_recencia'] = 1 / (site['idade_dias'] + 1)\n",
    "    return site\n",
    "\n",
    "site = atualizar_recencia(site)\n",
    "\n",
    "# Modificar a lógica de popularidade para incluir recência\n",
    "def recomendar_por_cluster_com_recencia(self, cluster, n=10):\n",
    "    artigos = self.popularidade_cluster.get(cluster, {})\n",
    "    df = pd.DataFrame.from_dict(artigos, orient='index', columns=['contagem'])\n",
    "    df = df.join(self.site.set_index('Page')[['peso_recencia']])\n",
    "    df['score'] = df['contagem'] * df['peso_recencia']\n",
    "    return df.sort_values('score', ascending=False).index.tolist()[:n]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
